#!/usr/bin/env python
import scraperwiki
import xlrd

#set a variable for the spreadsheet location
XLS = 'https://www.parliament.uk/documents/lords-finance-office/2016-17/allowances-expenses-2016-17-month-1-april.xlsx'
#use the scrape function on that spreadsheet to create a new variable
xlbin = scraperwiki.scrape(XLS)
#use the open_workbook function on that new variable to create another
book = xlrd.open_workbook(file_contents=xlbin)
#use the sheet_by_index method to open the first (0) sheet in variable 'book' - and put it into new variable 'sheet'
sheet = book.sheet_by_index(0)
#use the row_values method and index (1) to grab the second row of 'sheet', and put all cells into the list variable 'title'
title = sheet.row_values(0)
#print the string "Title:", followed by the third item (column) in the variable 'title' 
print "Title:", title[0]
#put cells from the 15th row into 'keys' variable 
keys = sheet.row_values(5)
record = {}
#loop through a range - from the 16th item (15) to a number generated by using the .nrows method on 'sheet' (to find number of rows in that sheet)
#put each row number in 'rownumber' as you loop
for rownumber in range(7, sheet.nrows):
    print rownumber
    record['Name'] = sheet.row_values(rownumber)[1]
    record['Code'] = sheet.row_values(rownumber)[2]
    record['Location'] = sheet.row_values(rownumber)[3]
    record['Attended'] = sheet.row_values(rownumber)[4]
    record['Away'] = sheet.row_values(rownumber)[5]
    record['Allowance'] = sheet.row_values(rownumber)[6]
    record['title'] = title[0]
    print "---", record
    scraperwiki.sqlite.save(["Name"], record)
