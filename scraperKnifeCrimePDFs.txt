#import the libraries we'll need

import scraperwiki
import urllib2
import lxml.etree
import lxml.html

#<table summary="Corporate level publications: What our priorities are and how we are doing: Knife Crime Summaries" class="foidocuments">

#This creates a new function to find the part of the page we want, scrape bits, and follow links in it.
def scrapetable(root):
    #Grab any bits of 'root' that have the tag <table> containing summary=" and 'Knife' somewhere in that, then the contents of <tr>. Put the results in variable called 'rows'
    rows = root.xpath(".//table[contains(@summary, 'Knife')]//tr")
    #That will be a list, so we start a for loop to go through each item, calling it 'row'
    for row in rows:
        #show us the text content of that object
        print row.text_content()
        #create an empty variable 'record', which is a dictionary
        record = {}
        uniqueid = 0
        #now grab the contents of all <td><a tags within that 'row' object, and put it in the variable 'report'
        report = row.cssselect("td a")
        #if that exists...
        if report:
            #show us the value of the first (index 0) 'title=' attribute
            pdfurl = report[0].attrib.get('href')
            record["Date"] = report[0].attrib.get('title')
            record["URL"] = report[0].attrib.get('href')
#            print record
            if pdfurl:
                pdfdata = urllib2.urlopen(baseurl+pdfurl).read()
                xmldata = scraperwiki.pdftoxml(pdfdata)
                pdfxml = lxml.etree.fromstring(xmldata)
                print xmldata
                boldtags1 = pdfxml.xpath('.//text[contains(@top, "191")]//b')
                record ["Date2"] = boldtags1[0].text
                boldtags = pdfxml.xpath('.//text[contains(@top, "386")]//b')
#<text top="386" left="464" width="75" height="21" font="0"><b>04/09/2012</b></text>
                record ["Review Date"] = boldtags[1].text
                print record
#                Brent = pdfxml.xpath('.//text[contains(@top, "173")]')
                texttags = pdfxml.xpath('.//text')
                for text in texttags:
                    left = text.attrib.get('left')
#PROBLEM WITH THIS LINE - RETURNS NONE because RIGHT IS NOT AT ATTRIBUTE OF TEXT
                    right = text.attrib.get('right')
                    #convert the attribute from a string into an integer:
                    leftinteger = int(left)
#IF leftinteger is between 96 and 99
#Literally? If 96 is smaller than leftinteger, and leftinteger is smaller than 99:
#see other options at http://stackoverflow.com/questions/618093/how-to-find-whether-a-number-belongs-to-a-particular-range-in-python
                    if 96 < leftinteger < 99:
#                    if left == '97' or left == '98':
                        record ["BOCUname"] = text.text
                        print record
                    if 324 < leftinteger < 327:
                        record ["Offences"] = text.text
                        print record
                    if 405 < leftinteger < 408:
                        record ["Sanction_detentions"] = text.text
                        print record
                    if 481 < leftinteger < 484:
                        record ["Sanction_detention_rate"] = text.text
                        print record
                    if 587 < leftinteger < 590:
                        record ["Offences FYTD_2011_12"] = text.text
                        print record
                    if 661 < leftinteger < 664:
                        record ["Offences FYTD_2012_13"] = text.text
                        print record
                    if 713 < leftinteger < 716:
                        record ["Offences percentage change"] = text.text
                        print record
                    if 812 < leftinteger < 815:
                        record ["Sanction detections FYTD 2011_12"] = text.text
                    if 887 < leftinteger < 890:
                        record ["Sanction Detections FYTD_2012_13"] = text.text
                    if 943 < leftinteger < 946:
                        record ["Sanction Detection rate FYTD 2011_12"] = text.text
                    if 1021 < leftinteger < 1024:
                        record ["Sanction Detections rate FYTD 2012_13"] = text.text
                        uniqueid = uniqueid+1
                        record ["uniqueid"] = uniqueid
                        print record
                        scraperwiki.sqlite.save(["uniqueid"], record)                    


#This creates a new function to scrape the initial page so we can grab report titles and the links
def scrape_and_look_for_next_link(url):
    #scrapes the page and puts it in 'html'
    html = scraperwiki.scrape(url)
    print html
    #turns html from a string into an lxml object called 'root'
    root = lxml.html.fromstring(html)
    #runs another function - created earlier - on 'root'
    scrapetable(root)

#This will be used for relative links in later pages
baseurl = "http://www.met.police.uk/foi/"
#When added to the baseurl, this is our starting page 
startingurl = "c_priorities_and_how_we_are_doing.htm"

#Run the function created earlier above on that URL
scrape_and_look_for_next_link(baseurl+startingurl)


#COPY ACROSS CODE FROM PREVIOUS SCRAPER PT3